{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a00efd3-e78d-4403-9582-29f1ca9f1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import  time\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import  img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import  BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from TV_UNET import get_unet, TV_bin_loss\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import backend as K \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95e1ab2b-88cf-4dec-bbe4-d49463b13c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## TV-Unet\n",
    "\n",
    "'''#########################################################################'''\n",
    "\n",
    "num_class=2\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "'''#########################################################################'''\n",
    "def get_unet(input_img, n_filters = 64, dropout = 0.2, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(num_class, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "'''#########################################################################'''\n",
    "def TV_bin_loss(y_true, y_pred):\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "\n",
    "  bin_loss = binary_crossentropy(y_true_f,y_pred_f )\n",
    "    \n",
    "  images=y_pred[:,:,:,1]\n",
    "  value = tf.reduce_mean(tf.abs(images[:,1:,:] - images[:,:-1,:])) + \\\n",
    "            tf.reduce_mean(tf.abs(images[:,:,1:] - images[:,:,:-1]))\n",
    "\n",
    "  return 2.4e-7*value + bin_loss\n",
    "\n",
    "\n",
    "def dice_coef(y_pred, y_true):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    layer_names=[layer.name for layer in model.layers]\n",
    "    for l in layer_names:\n",
    "        if l==layer_names[-1]:\n",
    "            value = TV_bin_loss(y_true, y_pred)\n",
    "        else:\n",
    "            value = binary_crossentropy(K.flatten(y_true),K.flatten(y_pred))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4567934-6f3d-4bab-b3ac-b9c72fedacd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['X_train', 'X_valid', 'label_test', 'y', 'y_train']>\n"
     ]
    }
   ],
   "source": [
    "############3 Collecct dataset\n",
    "\n",
    "'''#########################################################################'''\n",
    "\n",
    "im_width = 128\n",
    "im_height = 128\n",
    "EpoachesNo=100\n",
    "BatcheSZE=32\n",
    "num_class=2\n",
    "\n",
    "# read datasets\n",
    "\n",
    "combined_data = h5py.File(\"h5_datasets/combined_CT_datasets.h5\", \"r\")\n",
    "\n",
    "#print(combined_data.keys())\n",
    "\n",
    "X_train = np.array(combined_data[\"X_train\"])\n",
    "X_valid = np.array(combined_data[\"X_valid\"])\n",
    "label_test = np.array(combined_data[\"label_test\"])\n",
    "y = np.array(combined_data[\"y\"])\n",
    "y_train = np.array(combined_data[\"y_train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecf4ec-4a89-4af8-bdf9-85594eba9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 16:40:42.107790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.142053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.142395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.144045: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-10 16:40:42.145121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.145408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.145644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.916444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.916785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.917058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 16:40:42.917361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 192 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "2022-02-10 16:40:42.930881: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 192.75M (202113024 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "############### Train model\n",
    "\n",
    "input_img = Input((im_height, im_width,1), name='img')\n",
    "\n",
    "model = get_unet(input_img, n_filters=64, dropout=0.2, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001) , loss = [my_loss], metrics=['accuracy',dice_loss,Recall(name='recall_1'),\n",
    "                                                            Precision(name='pre_1')])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "'''#########################################################################'''\n",
    "############ Split train and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, mask, test_size=0.1, random_state=42)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=50, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-TV-UNet1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "results = model.fit(X_train, y_train, batch_size=32, epochs=10, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1438ca-952e-4011-860d-6d828fea832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
