# COVID TV-UNet: Segmenting COVID-19 Chest CT Images Using Connectivity Imposed U-Net

The main contributions of our work can be summarized as
follows:

• Development of a novel connectivity-promoting
regularization loss function for an image segmentation
framework detecting pathologic COVID-19 regions in
pulmonary CT images.

• Quantitative validation showing improved performance attributable to our new TV-UNet approach
compared to published state-of-the-art segmentation
approaches.


# COVID CT SEGMENTATION DATASET
we used some different datasets:

1. all available data from the COVID-19 CT segmentation dataset [1], consisting of 929 CT slices from 49 patients. Out of these, 473 CT-image slices are labeled as including COVID-19 pathologies with Ground-Glass pathology regions identified by expert tracing. The remaining 456 CT image slices are labeled as COVID-19 pathology free. CT-slice sizes were either 512×512 or 630×630. While a small subset of the 929 CT images also have regions of additional pathologies identified and labeled as Consolidation and/or Pleural Effusion, this work focuses on the Ground Glass mask.

2. One such dataset with semi-supervised COVID-19 segmentations (COVID-SemiSeg) was recently reported in [2]. The COVID-SemiSeg dataset consists of two sets. The first one contains 1600 pseudo labels generated by Semi-InfNet model and 50 labels by expert physicians. The second set includes 50 multi-class labels. Overall, there are 48 images
that can be used for performance-comparison assessment and these CT data were used to compare our TV-Unet approach with other methods.

[1] COVID-19 CT segmentation dataset, link: https://medicalsegmentation.com/covid19/, accessed: 2020-04-11.

[2] COVID-SemiSeg Dataset, link: https://arxiv.org/pdf/2004.14133.pdf

# Training, Validation, and Testing Sets
1. First dataset: 

To evaluate the effect of radically different training/testing set composition and to demonstrate the robustness of the obtained results, two different splits of training, validation, and testing sets are selected from [this dataset](http://medicalsegmentation.com/covid19/).

In Split 1, data from a relatively large number of 46
training/validation-set patients and a small number of only 3
testing-set patients were used. 729 CT image slices formed the
training and validation sets, and 200 images the testing set. The number of slices in this split can be seen in [main_TV_Unet_Split1.py](https://github.com/narges-sa/COVID-CT-Segmentation/blob/readme-changes/main_TV_Unet_Split1.py) code.

In Split 2, a more balanced distribution of patient numbers was
used with 654 CT image slices from 35 patients included in the
training and validation sets, and 275 images from 14 patients
formed the testing set.

2. The second dataset:

To compare TV-UNet model with the Inf-Net and other promising image
segmentation models trained on COVID-SemiSeg dataset, including UNet++, Semi-Inf-Net, DeepLab-v3,
FCN8s, and Semi-Inf-Net+FCN8s, training and testing sets are downloaded from [here](https://github.com/DengPingFan/Inf-Net). 

For this comparison just run [main_TV_Unet_inf.py](https://github.com/narges-sa/COVID-CT-Segmentation/blob/readme-changes/main_TV_Unet_inf.py) code.

![alt tag](https://github.com/narges-sa/COVID-CT-Segmentation/blob/readme-changes/results/normal%26COVID.jpg? )
 <p align="left">
  <img src="Fig. 1. The difference between normal and COVID-19 images" width="350" alt="Fig. 1. The difference between normal and COVID-19 images">
</p>



![alt text](https://github.com/narges-sa/COVID-CT-Segmentation/blob/readme-changes/results/COVID.jpg?raw=true "Title")
<p align="left">
  <img src="Fig. 2" width="350" alt="Fig. 2. Sample images from the COVID-19 CT segmentation dataset. The
first row shows two COVID-19 images. The red boundary contours in the
second row denote regions of COVID-19 Ground-Glass pathology and are not
a part of the original image data.The third row shows Ground-Glass masks">
</p>

# Visualization Results:
![alt text](https://github.com/narges-sa/COVID-CT-Segmentation/blob/readme-changes/results/maskB%26TV.jpg)
<p align="left">
  <img src="Fig. 3" width="350" alt="Fig. 3. Predicted segmentation masks by U-Net trained from scratch and the proposed TV-UNet for a typical sample images from the testing set.">
  </p>

# Usage Right:

This work is done by Narges Saeedizadeh, Shervin Minaee, Rahele Kafieh, Shakib Yazdani, and Milan Sonka (the previous editor in chief of IEEE TMI). 

The Arxiv version of the paper can be downloaded from [here](https://arxiv.org/pdf/2007.12303.pdf). 

If you find this work useful, you can refer our work as:

@article{
  title={COVID TV-UNet: Segmenting COVID-19 Chest CT Images Using Connectivity Imposed U-Net},
  
  author={Saeedizadeh, Narges and Minaee, Shervin and Kafieh, Rahele and Yazdani, Shakib and Sonka, Milan},
  
  journal={arXiv preprint arXiv:2007.12303},
  
  year={2020}
}
